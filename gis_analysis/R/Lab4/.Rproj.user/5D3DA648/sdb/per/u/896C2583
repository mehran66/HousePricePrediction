{
    "contents" : "mapClassifyFeatures <- function(Data, inputVar, numClasses, type ){\n  \n  library(maptools)\n  \n  library(classInt)  # Library for creating clases\n  # Create Categories based on quantiles\n  cats = classIntervals(inputVar, n=numClasses, style= type)\n  library(RColorBrewer)\n  # Save palette as an object\n  pal = brewer.pal(numClasses, \"YlGnBu\") \n  cols = findColours(cats, pal) \n  \n  # Draw map using specificed data and colors\n  # lty=0 (line type) turns off tract borders\n  plot(chicago, col=cols, lty=0)\n}\n\n------------------\nchicago@data = chicago@data[-c(82, 520),]\n4-1- LM summary \n```{r echo=FALSE}\nmod1 = lm(adj_Weapons_Violation ~ sqrt(Number_of_violent_crimes) +\n            sqrt(Percent_of_children_in_single_female_headed_household) + \n            sqrt(PCT_of_Households_with_cash_public_assistance) + \n            sqrt(Disorderly_Conduct),\n          data=chicago@data)\n```\n\n```{r}\nsummary(mod1)\n```\n4-2- Interpret model coefficients/p-values, model rˆ2/F-Test\n\n```{r eval=F}\n\"Most of the variables are significant, except, Number_of_violent_crimes, Percent_of_children_in_single_female_headed_household, and Disorderly_Conduct.\n\nThe R-square is fine (0.6204) that means our dependent variales explains msot of the variability of the adj_Burglary in the the regression model.\n\nThe p-value of our model is very small and it means that there is a significant relationship between the variables in the regression model.\n\nPercent_of_children_in_single_female_headed_household and Percent_Less_than_High_School_Education_ coefficients seems sucpitious, because their increase lead to decrease in the violent crime\n\"\n```\n\n4-3- Model Diagnostics \n\n4-3-1- Residual plots\n\n\n\n```{r}\nplot(mod1)\nhist(resid(mod1))\nplot(resid(mod1) ~ predict(mod1))\nabline(0, 0) # the horizon\n```\n\n4-3-1-1- Heteroskedasticity (non-constant variance)\n\n```{r}\n# Evaluate heteroscedasticity\n# If the test is positive (low p value), you should see if any transformation of the dependent variable helps you eliminate heteroscedasticity\nlibrary(zoo)\nlibrary(lmtest)\nbptest(mod1)\n```\n\n```{r eval=F}\n\" There is heteroscedasticity\n\"\n```\n\n4-3-1-2- Influential observations (possible outliers)\n```{r}\n# Bonferroni p-values to assesse Outliers\nlibrary(car) \noutlierTest(mod1) # Bonferonni p-value for most extreme obs\n```\n\n```{r eval=F}\n\" There are 1 outliers based on Bonferroni test (82). But 520, 235, 420, 1nd 433 also is apparantly outliers based on the regression plots.\n\"\n```\n\n4-3-1-3- pattern (Nonlinearity)\n\n```{r}\n# When the residuals bounce randomly around the 0 line, it suggests that the assumption that the relationship is linear is reasonable\n# Evaluate Nonlinearity\n# component + residual plot \ncrPlots(mod1)\n```\n\n```{r eval=F}\n\" Vandalism are not linear.\n\"\n```\n4-3-1-4- Normality of Residuals\n\n```{r}\nqqPlot(mod1, main=\"QQ Plot\") #qq plot for studentized resid \n\n# distribution of studentized residuals\nlibrary(MASS)\nsresid <- studres(mod1) \nhist(sresid, freq=FALSE, \n     main=\"Distribution of Studentized Residuals\")\nxfit<-seq(min(sresid),max(sresid),length=40) \nyfit<-dnorm(xfit) \nlines(xfit, yfit)\n\n#Null hypothesis residuals are normally distributed \nshapiro.test(resid(mod1))\n```\n\n```{r eval=F}\n\" Residuals are nearly normal. It seems there are some outliers.\n\"\n```    \n\n4-3-1-5- Non-independence of Errors\n\n```{r}\n# Test for Autocorrelated Errors (verifies if the residuals from a linear model are correlated        or not)\nlibrary(car)\ndurbinWatsonTest(mod1)\n\n# The null hypothesis (H0H0) is that there is no correlation among residuals, i.e., they are           independent.\n# The alternative hypothesis (HaHa) is that residuals are autocorrelated.\n```\n\n```{r eval=F}\n\" Residuals are autocorrelated\n\"\n```   \n\n4-3-2- map residuals\n\n```{r echo=FALSE}\n# When the residuals from a model show clear spatial patterns there is evidence of some sort of     missing variable.\nmapClassifyFeatures(chicago, resid(mod1), 5, \"jenks\", \"YlOrRd\" )\n```\n\n```{r eval=F}\n\"  There is not a clear spatial pattern in the residual map.\n\"\n```  \n\n4-3-3- check for multicollinearity (VIF) (Note: the cutoff is 2.5)\n\n```{r }\n# Evaluate Collinearity\nlibrary(car)\nvif(mod1) # variance inflation factors \n```\n\n```{r eval=F}\n\" \nThe cuttoff is 2.5, and here 2 of them are higher than this cuttoff and we should eliminate 1 of them.\nNumber_of_violent_crimes\nVandalism\n\"\n``` \n\n4-3-4- examine the partial R-Square for each variable\n\n```{r }\nlibrary(lmSupport)\nmodelEffectSizes(mod1)\n\n```\n\n```{r eval=F}\n\" \nFrom the table generated from this function, the pEta-sqr is highest for Vandalism, at 0.2163, \nand lowest for Percent_of_children_in_single_female_headed_household, at 0.0006. These pEta-sqr values reflect the marginal contribution of each variable to the model, its impact on the model given that all other variables \nare already in the model. \n\"\n``` \n\n### 5 - Model adjustment\n5-1- What variables did you add/remove?\n\n```{r eval=F}\n\"A VIF test was conducted on the model to check variable multicolinearity. Results indicated that 2 variables may have correlations with one another. To compensate, 1 of the them were omitted:,\nI emiminated Number_of_violent_crimes.\n\"\n```\n\n```{r echo=FALSE}\nmod1_red1 = lm(adj_Burglary ~ Weapons_Violation +\n                 Percent_Less_than_High_School_Education_ +\n                 Number_of_property_crimes +\n                 Vandalism +\n                 Percent_of_children_in_single_female_headed_household +\n                 Disorderly_Conduct,\n               data=chicago@data)\n```\n\n5-2- check for multicollinearity (VIF)\n\nA VIF on reduced model is provided below. Removing these variables did improve the VIFs:\n  \n  ```{r echo=FALSE}\n# Evaluate Collinearity\nlibrary(car)\nvif(mod1_red1) # variance inflation factors \n```\n\n```{r eval=F}\n\"now Weapons_Violation and Vandalism are colinear.\n\"\n```\n\n5-3- Diagnostic tests: AIC, Anova, extra sum of squares (modelEffectSizes, partial R-Squared), etc. \n```{r }\n# Akaike Information Criterion (AIC)\n# Small values are desirable\nAIC(mod1) # 2042.116\nAIC(mod1_red1) # 2040.859\n# AIC has decresed\n\n#Anova: it tests whether reduction in the residual sum of squares are statistically significant or not\n#anova(mod1, mod1_red1)\n#I do not know why Anova does not work\n\n\n# extra sum of squares (modelEffectSizes, partial R-Squared)\nmodelEffectSizes(mod1_red1)\n# Vandalism had the highest partial sum of squares value, at 0.1973, showing it contributed most to the violent crime model. Percent_of_children_in_single_female_headed_household, on the other hand has the smallest partial sum of square\n```\n\n### 6 - Further model specification/diagnostics \n6-1- Follow the same workflow as the \"1st Model Specification\"/\"Model adjustment\" sections. You should aim to run through ˜2 more model iterations.  Keep in mind that your final model does not need to be perfect, you will be explaining its shortcomings in the final model summary.\n\n\n```{r }\n#I ran the model several more times and here is the final model:\n\nmod1_final = lm(adj_Burglary ~ Population_Density + \n                  Liquor_License +\n                  sqrt(Vandalism)+\n                  sqrt(Drug_Abuse),\n                data=chicago@data)\n\nsummary(mod1_final)\n\n# first of all, there were some outliers in the residuals. I tried to eliminate them, but it was an infinit loop. After eliminating Number_of_property_crimes, I did not have that problem. So It seems that thre are some outlires in the Number_of_property_crimes that affects the model.\n\n# We tranform the Vandalism and Drug_Abuse using SQRT, and it significantly improve the model. \n\n# This model has the the smallest AIC (1952.287)\n\n# Still this model has homoscedasticity and the residuals are autocorrelated.\n\n# I eliminated some of the variables due to colinearity\n\n# Vandalism had the highest partial sum of squares value, at 0.1973, showing it contributed most to the violent crime model. Drug_Abuse, on the other hand has the smallest partial sum of square\n```\n\n\n### 7 - Final Model Summary\n7-1- In what ways does your final model explain the crime type you chose? Pay special attention to the sign and significance of each variable. Do the predictors align with your intuition about the association between social/economic characteristics and the frequency of crime?\n\n```{r eval=F}\n\" To explain our crime type (number of Vehicle Theft, we came up with four variable that can explain the variation of our model better. \n1) Population_Density: this variable is significant, its increase leads to increasing in the number of violent crime. 2) Liquor_License is a fine variable in our model and with a positive coefficient has a direct relationship with number of Vehicle Theft. This predictor also align with my intuition about the association between social/economic characteristics and the number of violent crime. 3) vandalism was the most statistically significant variable of this model. This may be due to vehicle theft and vandalism as co-occurring events, as well as increasing escalation of crimes and/or opportunity for crime. 4) Finally, Drug_Abuse that although is not a significant variable but differnet tests proved that it's an effective variable in our model. \n\"\n```\n7-2- What shortcomings does your final model have? In what ways is the model's explanatory power limited? Does the model still violate assumptions of OLS regression (i.e. heteroskedasticity, residual [spatial]autocorrelation)? (Explain how these problems limit your ability to draw inferences about the crime type you chose.) How might the characteristics of the variables you chose influence these problems? [*]\n```{r eval=F}\n\"\nOur final model has a R-square of 0.5054 that is considered fine in a linear regression model, but still the results are not completly satisfying. First of all, still there are outliers in our residuals. It seems that deleting outliers in not an straight forward process. Also we still have heteroscedasticity and correlated residuals in our model. After examining the plots of residuals vs variables, the residuals for vandalism does not bounce randomly around the 0 line, it suggests that the assumption that the relationship is linear is not reasonable. But I ploted vandalism and Vehicle Theft together and it's clear that they have a very strong linear relationship. I do not know what is exactly the reason of this issue.\n\"\n```",
    "created" : 1456635208874.000,
    "dirty" : true,
    "encoding" : "",
    "folds" : "",
    "hash" : "2193156664",
    "id" : "896C2583",
    "lastKnownWriteTime" : 1425366914,
    "path" : null,
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "type" : "r_source"
}